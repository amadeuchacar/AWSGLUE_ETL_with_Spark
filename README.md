# Projeto - ETL utilizando AWS Glue e Spark

Projeto realizado no curso "*Data Lake in AWS - Easiest Way to Learn*".

## Objetivo üéØ
Realizar um processo de ETL em um arquivo que possui dados entre 2017 e 2022 de um ranking global de universidades, utilizando o AWS Glue em conjunto com o Spark, com as seguintes etapas:
1. Extrair um arquivo *.csv* de um bucket S3;
2. Realizar a transforma√ß√£o deste arquivo, realizando um pr√©-processamento (limpeza de dados);
3. Carregar este arquivo transformado em um outro bucket S3;

## Requisitos üìÑ
1. Bucket S3 com o arquivo *.csv*, presente neste reposit√≥rio dentro do diret√≥rio "csv";
2. Database no AWS Glue, que ir√° armazenar as tabelas do arquivo *.csv* que ser√° lido;
3. Crawler do AWS Glue para capturar os metadados do arquivo *.csv* lido e construir uma tabela com os dados;
4. Jupyter notebook com o c√≥digo de ETL presente neste reposit√≥rio no diret√≥rio "*notebooks*";
5. Bucket S3 destino, onde ser√° carregado o arquivo ap√≥s o processo de ETL;

## Desenvolvimento do c√≥digo de ETL üë®üèª‚Äçüíª

Todas estas etapas est√£o comentadas no arquivo do notebook presente neste reposit√≥rio.

### 1Ô∏è‚É£ Primeira etapa - Cria√ß√£o do ambiente
1. Cria√ß√£o do ambiente Spark, in√≠cio de sess√£o do Spark e do Glue;
2. Importa√ß√£o de vari√°veis de ambiente para proteger dados sens√≠veis (nome do banco de dados criado no Glue, da tabela gerada pelo Crawler, do *Transformation Context* e o path do bucket S3 destino);

### 2Ô∏è‚É£ Segunda etapa - Trabalhando com os dados
1. Importar os dados para o ambiente do notebook, puxando os dados da tabela criada pelo Crawler para uma vari√°vel do tipo DynamicFrame;
2. Converter o DynamicFrame para DataFrame para facilitar o trabalho;
3. Realizar os processo de limpeza (transforma√ß√£o dos dados), utilizando Spark SQL;
4. Com os dados transformados, voltar esses dados para uma vari√°vel DynamicFrame;

### 3Ô∏è‚É£ Terceira etapa - Carregar os dados
1. Carregar os dados armazenados na vari√°vel do tipo DynamicFrame para um arquivo que ser√° armazenado no bucket S3 de destino, conforme caminho do destino especificado;
2. Commit no job do Glue, para que o Glue possa rastrear os dados que j√° foram processados;
